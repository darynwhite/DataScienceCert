{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Markov Chains in Python\n",
    "\n",
    "Markov chains are an example of how simple ideas in probabilities can be extended to create sophisticated models that capture change over time in a dynamic system. Markov chains form the basis of some very powerful methods such as **Markov chain Monte Carlo (MCMC)** models used to generate samples from the posterior distribution in Bayesian models. Markov chains can also be further extended to create other models such as **hidden Markov models (HMMs)**.\n",
    "\n",
    "There is a lot of theory to Markov chains, some of which addressed in the slides, but in this notebook we focus on a simple example to illustrate the idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn import naive_bayes\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = [15, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the tennis data to run our example. For this example, we assume that the tennis data **is sorted by date and the rows correspond to consecutive days**. This is not necessarily true of this data set. It's just an assumption we make so we can illustrate Markov chains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outlook</th>\n",
       "      <th>temp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windy</th>\n",
       "      <th>play</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sunny</td>\n",
       "      <td>hot</td>\n",
       "      <td>high</td>\n",
       "      <td>strong</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sunny</td>\n",
       "      <td>hot</td>\n",
       "      <td>high</td>\n",
       "      <td>weak</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>overcast</td>\n",
       "      <td>hot</td>\n",
       "      <td>high</td>\n",
       "      <td>weak</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rain</td>\n",
       "      <td>mild</td>\n",
       "      <td>high</td>\n",
       "      <td>weak</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rain</td>\n",
       "      <td>cool</td>\n",
       "      <td>normal</td>\n",
       "      <td>weak</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    outlook  temp humidity   windy play\n",
       "0     sunny   hot     high  strong   no\n",
       "1     sunny   hot     high    weak   no\n",
       "2  overcast   hot     high    weak  yes\n",
       "3      rain  mild     high    weak  yes\n",
       "4      rain  cool   normal    weak  yes"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tennis = pd.read_csv('../../data/tennis.csv')\n",
    "tennis.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only column we need here is `outlook`. Since we are assuming (for the sake of argument) that each row is a consecutive day, we can think of `outlook` as the outlook today and lag it by 1 day to get the outlook yesterday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yesterday</th>\n",
       "      <th>today</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sunny</td>\n",
       "      <td>sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sunny</td>\n",
       "      <td>overcast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>overcast</td>\n",
       "      <td>rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rain</td>\n",
       "      <td>rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rain</td>\n",
       "      <td>rain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  yesterday     today\n",
       "1     sunny     sunny\n",
       "2     sunny  overcast\n",
       "3  overcast      rain\n",
       "4      rain      rain\n",
       "5      rain      rain"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlook = pd.concat([tennis['outlook'].shift(1), tennis['outlook']], axis = 1).dropna()\n",
    "outlook.columns = ['yesterday', 'today']\n",
    "outlook.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now get counts from the above tables to see how the `outlook` transitions from yesterday to today."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>today</th>\n",
       "      <th>overcast</th>\n",
       "      <th>rain</th>\n",
       "      <th>sunny</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yesterday</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>overcast</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rain</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sunny</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "today      overcast  rain  sunny\n",
       "yesterday                       \n",
       "overcast          1     2      1\n",
       "rain              1     2      1\n",
       "sunny             2     1      2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(outlook['yesterday'], outlook['today'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we turn the counts into percentages, we get our transition matrix. To do this, we can just use the `normalize = 1`, where 1 here refers to normalizing **by column**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>yesterday</th>\n",
       "      <th>overcast</th>\n",
       "      <th>rain</th>\n",
       "      <th>sunny</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>today</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>overcast</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rain</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sunny</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "yesterday  overcast  rain  sunny\n",
       "today                           \n",
       "overcast       0.25  0.25    0.4\n",
       "rain           0.50  0.50    0.2\n",
       "sunny          0.25  0.25    0.4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_mat = pd.crosstab(outlook['today'], outlook['yesterday'], normalize = 1)\n",
    "tr_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "- Let's say that today's weather is overcast. Using the above transition matrix, predict tomorrow's weather. In other words, given the weather today, what is the probability distribution of the weather tomorrow. HINT: To do this, first we need to think how we can encode the fact that today's weather is overcast, and then we need to perform a matrix multiplication using `np.dot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tomorrow's weather by probability:\n",
      "\tovercast: 0.2875\n",
      "\train: 0.425\n",
      "\tsunny: 0.2875\n"
     ]
    }
   ],
   "source": [
    "tom = np.dot(tr_mat, tr_mat['overcast'])\n",
    "print(f\"Tomorrow's weather by probability:\\n\\tovercast: {tom[0]}\\n\\train: {tom[1]}\\n\\tsunny: {tom[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Assuming that today's weather is overcast, now find the distribution of the weather 2 days from today?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day after tomorrow's weather by probability:\n",
      "\tovercast: 0.29312499999999997\n",
      "\train: 0.41374999999999995\n",
      "\tsunny: 0.29312499999999997\n"
     ]
    }
   ],
   "source": [
    "day2 = np.dot(tr_mat,(np.dot(tr_mat, tr_mat[\"overcast\"])))\n",
    "print(f\"Day after tomorrow's weather by probability:\\n\\tovercast: {day2[0]}\\n\\train: {day2[1]}\\n\\tsunny: {day2[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Assuming that today's weather is overcast, now calculate and print the distribution of the weather over the next 10 days. How do the probabilities change over time? HINT: To code this in a clean way, it's best to avoid calling the matrix multiplication recursively. So instead, we write a loop to implement the recursion. We laid out a lot of the code here already. You just need to add two additional lines of code to implement this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.25       0.5        0.25      ]\n",
      " [0.2875     0.425      0.2875    ]\n",
      " [0.293125   0.41375    0.293125  ]\n",
      " [0.29396875 0.4120625  0.29396875]\n",
      " [0.29409531 0.41180937 0.29409531]\n",
      " [0.2941143  0.41177141 0.2941143 ]\n",
      " [0.29411714 0.41176571 0.29411714]\n",
      " [0.29411757 0.41176486 0.29411757]\n",
      " [0.29411764 0.41176473 0.29411764]\n",
      " [0.29411765 0.41176471 0.29411765]]\n"
     ]
    }
   ],
   "source": [
    "n_iter = 10 # number of days\n",
    "A = [1, 0, 0] # weather today\n",
    "probs = np.ones((n_iter, 3)) # a matrix to store the distributio of probabilites\n",
    "\n",
    "for i in range(n_iter):\n",
    "    ## store the distribution of weather in ith row of probs\n",
    "    next = np.dot(tr_mat, A)\n",
    "    ## update the distribution of weather\n",
    "    probs[i,:] = next\n",
    "    A = next\n",
    "    \n",
    "\n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using the long term distribution of weather, we can also generate daily weather data. To see how, run the cell below multiple times and see how the results change. We are using the **multinomial distribution** to generate the samples here. This distribution is an extension of the **binomial distribution** to more than two outcomes. Sampling from it is like throwing a biased n-sided die where each side has its own probability of being rolled (if the die were fair, all probabilities would be equal to $1/n$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.multinomial(1, A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should see that the probabilities seem to stabilize very quickly, and once stabilized, the system reaches some sort of equilibrium. Of course this only happens if certain conditions are met, which is addressed by the theory of Markov chains, but we will leave it here.\n",
    "\n",
    "### End of exercise\n",
    "\n",
    "There are many immediate applications to Markov chains. As one example, consider how a Markov chain model could be used to create a word completion algorithm or even a sentence completion algorithm. Of course such an algorithm would make some very simplistic assumptions and there are far better alternatives we can use these days, but many of the state-of-the-art algorithms today are also often based on simple ideas. Another thing to note is that because Markov chains are based on probabilities, once we get the long term probabilities we can \"generate\" new examples as we saw in the exercise. This means that Markov chains are also a \"generative model\", i.e. we can use them to generate new words or new sentences (not necessarily grammatically correct). Generative models are very useful in artificial intelligence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to naive Bayes models\n",
    "\n",
    "This notebook introduces you to naive Bayes models. Naive Bayes models are a surprisingly useful and effective simplification of the general Bayesian models. Naive Bayes models make the naive assumption of independence of the features.\n",
    "\n",
    "Some properties of naive Bayes models are:\n",
    "\n",
    "- Computational complexity is linear in number of parameter / features\n",
    "- Require minimal data to produce models that generalizes well\n",
    "- Have a simple and inherent regularization\n",
    "\n",
    "Naive Bayes models are widely used including for:\n",
    "\n",
    "- Document classification\n",
    "- SPAM detection\n",
    "- Image classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example - income prediction using Census data\n",
    "\n",
    "Let's try a binary classification example on some sample US Census data. We want to build and evaluate a naive Bayes model to classify people by high and low income using $50,000 as the cut-off. Execute this code and examine the features in the data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census = pd.read_csv('../data/census.csv', sep = ',\\\\s+', engine = 'python')\n",
    "census.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see some features which are likely to be collinear. There is also one feature, `fnlwgt`, which is not useful in classifying these people. We also convert all columns of type `object` into type `category`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census = census.drop(columns = ['workclass', 'fnlwgt', 'education-num', 'relationship'])\n",
    "census[census.select_dtypes('object').columns] = census.select_dtypes('object').astype('category')\n",
    "census.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute a naive Bayes model to classify `income` using the features in the Income data set. Since we have a mix of categorical and numeric features, we need to train two separate naive Bayes classifiers and then combine their results at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_num = census.select_dtypes('int64')\n",
    "features_cat = census.drop(columns = ['income']).select_dtypes('category').apply(lambda x: x.cat.codes)\n",
    "# X = pd.concat([features_num, features_cat], axis = 1)\n",
    "Y = census['income'].cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now train our classifier. Read [here](https://scikit-learn.org/stable/modules/naive_bayes.html#multinomial-naive-bayes) about the hyper-parameters of the naive Bayes classifier. Since we have a mix of categorical and numeric features, we train a separate classifier on the categorical features and numeric features. We will later combine them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = naive_bayes.CategoricalNB()\n",
    "mnb.fit(features_cat, Y)\n",
    "\n",
    "gnb = naive_bayes.GaussianNB()\n",
    "gnb.fit(features_num, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although naive Bayes can be a good classifier, it is not necessarily a good estimator, so the soft predictions obtained from `predict_proba` should be viewed with caution. So we should not be too eager in interpreting the soft predictions as probabilities, but we can definitely compare them across the different categories to see each category's contribution to the final (posterior) probability. Here we can see that for the categories of `education`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd_0 = pd.DataFrame({'cat': census['education'].cat.categories, 'prob': np.exp(mnb.feature_log_prob_[0][0])})\n",
    "dd_1 = pd.DataFrame({'cat': census['education'].cat.categories, 'prob': np.exp(mnb.feature_log_prob_[0][1])})\n",
    "dd_0['y'] = 'income is low'\n",
    "dd_1['y'] = 'income is high'\n",
    "dd = pd.concat([dd_0,dd_1], ignore_index=True)\n",
    "\n",
    "# let's keep only the relevant categories and order them in a way that makes sense\n",
    "cat_order = ['HS-grad', 'Prof-school', 'Assoc-voc', 'Assoc-acdm', 'Bachelors', 'Masters', 'Doctorate']\n",
    "dd['cat'] = dd['cat'].astype('category').cat.set_categories(cat_order)\n",
    "\n",
    "bar = sns.barplot(x = 'cat', y = 'prob', data = dd, hue = 'y');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the numeric feature, we can try to visualize the results by looking at how the posterior probabilities change as a result of changing one variable (holding the others constant at their average values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_min, age_max = features_num.describe()['age'][['min', 'max']]\n",
    "age_range = np.linspace(age_min, age_max, num = 50)\n",
    "dd = pd.DataFrame({'age': age_range})\n",
    "\n",
    "dd['capital-gain'] = features_num['capital-gain'].mean()\n",
    "dd['capital-loss'] = features_num['capital-loss'].mean()\n",
    "dd['hours-per-week'] = features_num['hours-per-week'].mean()\n",
    "\n",
    "sns.lineplot(x = age_range, y = gnb.predict_proba(dd)[:, 1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we had only one model, then we can obtain hard predictions by calling its `predict` model and get soft predictions by calling `predict_prob`. We can also indirectly obtain hard predictions by using `np.argmax` on the soft predictions.\n",
    "\n",
    "Since we need to combine both models into one, we need to do obtain hard predictions manually: \n",
    "- First we get soft predictions by taking the the product of each model's soft predictions (probabilities). Or in log terms, we add the log probabilites.\n",
    "- Finally we use `np.argmax` to get hard predictions from the soft predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_preds = mnb.predict_log_proba(features_cat) + gnb.predict_log_proba(features_num)\n",
    "combined_preds.shape\n",
    "census['pred_income_high'] = np.argmax(combined_preds, axis = 1)\n",
    "\n",
    "census.groupby('pred_income_high').mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(census['income'] == '>50K', census['pred_income_high'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How good a model is this? We leave it to the reader to try other performance measure or even try another model like logistic regression for comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "\n",
    "Document classification has been one of the most successful applications of the naive Bayes model. There is a good chance that the SPAM filter your email service uses is a naive Bayes model, at least in part.\n",
    "\n",
    "We say that we classify documents by **topics**. The naive Bayes topic model computes the probability that a document $D$ has topic $C$ based on the occurrence of the words $\\{ w_1, w_2, \\ldots, w_n \\}$, using the following relationship:\n",
    "\n",
    "$$p(C|D) \\propto \\prod_{j = 1}^N p(w_j|C)$$\n",
    "\n",
    "Notice that this topic model allows a document to have a number of topics. For example, we can say the topics of $D$ are the 5 topics with the highest probability.\n",
    "\n",
    "For a SPAM classifier, the topics are just spam and not spam, so we only need a Bernoulli topic model:\n",
    "\n",
    "$$p(S+|D) \\propto p(S+) \\prod_{j=1}^N p(w_j|S+)$$\n",
    "\n",
    "For this assignment we will use the `HouseVotes84` data which contains political party and votes on 16 important bills for 435 members of the US House of Representatives in 1984. We will use this data set to build and test a classifier to predict the political party of representatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn import naive_bayes\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = [15, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_names = [\n",
    "    'handicapped_infants',\n",
    "    'water_project_cost_sharing',\n",
    "    'adoption_of_the_budget_resolution',\n",
    "    'physician_fee_freeze',\n",
    "    'el_salvador_aid',\n",
    "    'religious_groups_in_schools',\n",
    "    'anti_satellite_test_ban',\n",
    "    'aid_to_nicaraguan_contras',\n",
    "    'mx_missile',\n",
    "    'immigration',\n",
    "    'synfuels_corporation_cutback',\n",
    "    'education_spending',\n",
    "    'superfund_right_to_sue',\n",
    "    'crime',\n",
    "    'duty_free_exports',\n",
    "    'export_administration_act_south_africa']\n",
    "\n",
    "votes = pd.read_csv('../data/house-votes-84.csv', \n",
    "                    header = None, names = ['party'] + vote_names)\n",
    "print(votes.shape)\n",
    "votes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Reshape the data from wide to long, so the new data called `votes_long` has only three columns: `party`, `issue` and `vote`. HINT: You can use the `melt` method to reshape the data. <span style=\"color:red\" float:right>[5 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## you code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Visualize the data by looking at a barplot of the frequency of votes by party for each issue. HINT: Use `sns.catplot`. <span style=\"color:red\" float:right>[5 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## you code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Return to the wide data `votes`: Loops though the columns `vote_names` and perform the following: <span style=\"color:red\" float:right>[15 point]</span>\n",
    "  - Convert the columns into type `category` and limit the categories to `y` and `n`. What happens with all the `?` votes?\n",
    "  - If there are missing values in these columns, replace the missing values with the majority vote **by party affiliation**. HINT: To look at an example, run `votes.groupby('party')['immigration'].transform(lambda x: x.fillna(x.mode()[0]))`.\n",
    "  - Replace a `yes` vote with 1 and a `no` vote with 0 (we do this because `sklearn` doesn't like string columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# votes.groupby('party')['immigration'].value_counts()\n",
    "# votes['immigration'].fillna(votes['immigration'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## you code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that no NAs are left in the data. Time to train a classifier to predict party affiliation based on how someone votes on the above issues. The model will predict the probability of being a Democrat. For simplicity, we assume that the probability of being a Republican is 1 minus that of being a Democrat.\n",
    "\n",
    "- Train a multinomial naive Bayes classifier to predict whether someone is a Democrat based on their vote. To keep things simple, you do NOT need to split the data into training and testing. <span style=\"color:red\" float:right>[10 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## you code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a new column in the data called `pred_party` and store the model's predicted party affilation in it. Note that you will need to express the predictions in terms of party affiliation: `democrat` or `republican`. <span style=\"color:red\" float:right>[10 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## you code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Get the accuracy and confusion matrix. <span style=\"color:red\" float:right>[5 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## you code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of assignment"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "data-sci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
