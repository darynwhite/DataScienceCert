{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "\n",
    "In this assignment we want to get comfortable with loading and manipulating data in Python. While future assignments will focus more using structured data which we can load into a `DataFrame` using `pandas`, this assignment is focused on semi-structured data and how we can \"flatten\" it and then load it into other formats. The objective is to see how data flows in Python from one object to another and what advantages and disadvantages each offers.\n",
    "\n",
    "Let's read the `books.json` data set and display the first item in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('../../data/books.json', encoding = 'utf-8') as f:\n",
    "    books_dict = json.load(f)\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(books_dict[0]) # print information for the first book"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Write a program that goes through the entire data and extracts the following information:  <span style=\"color:red\" float:right>[4 point]</span>\n",
    "\n",
    "  - title of the book\n",
    "  - name of the first author\n",
    "  - name of the second author (if book has more than one author)\n",
    "  - number of authors\n",
    "  - ISBN\n",
    "  - if the word \"data\" is in the book's description\n",
    "  - the number of words in the book's description\n",
    "  - the year the book was published\n",
    "\n",
    "  Of course because JSON data doesn't necessarily enforce any sort of schema, we can't be sure that the information we are trying to extract exists for every book. For example, if the book only has one author, then there is no second author. So use `try` and `except` as you loop through every book and skip to the next item every time some information is missing.\n",
    "\n",
    "  Store the extracted data in a list named `rows` whose elements are tuples, one tuple per book. For example, the first element of `rows` stores the tuple for the first book and should look like this:\n",
    "\n",
    "        ('Unlocking Android', 'W. Frank Ableson', 'Charlie Collins', 3, '1933988673', True, 252, 2009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Save the content of `rows` in a SQL-like table using `sqlite3`, and choose the appropriate column types. <span style=\"color:red\" float:right>[2 point]</span> \n",
    "\n",
    "  As your column names use the following:\n",
    "\n",
    "  - `title`\n",
    "  - `author_1`\n",
    "  - `author_2`\n",
    "  - `num_authors`\n",
    "  - `isbn`\n",
    "  - `has_data`\n",
    "  - `desc_len`\n",
    "  - `year_published`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Write a SQL query against the table to show all books that (1) contain the word \"data\" and (2) have more than 3 authors. Store the result of the query in an object called `books_table`, then close the connection. <span style=\"color:red\" float:right>[2 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQL tables are not the only way, and definitely not the most straightforward way to store and manipulate data in Python. A format that's more popular with data scientist is to use the `pandas` library to create a `DataFrame`. This library has a lot of functionality that makes it easy to run the common tasks data scientists do with data.\n",
    "\n",
    "4. Read the data from the above query into a `DataFrame` and call it `books_df`. HINT: Use `pd.DataFrame` and specify meaningful column names to use for the columns. <span style=\"color:red\" float:right>[1 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Display the first few columns of a `DataFrame` by calling its `head` method. <span style=\"color:red\" float:right>[1 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember how earlier we said that a `DataFrame` is built on top of `numpy` arrays? Another way of saying it is that a `DataFrame` is an **abstraction** on top of `numpy` arrays: i.e. a `DataFrame` is a more **high-level** object than a `numpy` array. \n",
    "\n",
    "6. Call the `values` attribute of your `DataFrame` to convert it into a numpy array and display the first 3 elements of the array. <span style=\"color:red\" float:right>[1 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can judge which object is more \"user-friendly\". That's one of the things that abstractions allow us to do: build more user-friendly (abstract) objects from less user-friendly (but more fundamental) objects.\n",
    "\n",
    "# End of assignment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
