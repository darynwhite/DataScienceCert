{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b60754b6",
   "metadata": {},
   "source": [
    "# Linear Normalization\n",
    "Most normalizations are linear normalizations  \n",
    "A linear normalization applies this pattern: \n",
    "\n",
    "`xNorm = (x - offset)/spread` \n",
    "\n",
    "Where: \n",
    "- x is a numeric variable\n",
    "- offset is a scalar that shifts variable x lower or higher\n",
    "- spread is a scalar that re-scales variable x to a smaller or larger spread\n",
    "- xNorm is the normalized variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7699edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f854704",
   "metadata": {},
   "source": [
    "## Different Linear Normalization Methods\n",
    "First we need an array that we can normalize\n",
    "We call this array a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a5e7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1,11,5,3,15,3,5,9,7,9,3,5,7,3,5,21.])\n",
    "X = pd.DataFrame(data = x, columns = ['x'])\n",
    "print(\" The original variable:\")\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9c0978",
   "metadata": {},
   "source": [
    "### Trivial Normalization\n",
    "- offset is 0\n",
    "- spread is 1\n",
    "In math a trivial process is one that doesn't change anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddac2044",
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = 0\n",
    "spread = 1 \n",
    "X['xNormTrivial'] = (x - offset)/spread\n",
    "print(\" Trivial normalization doesn't change values:\")\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3064f8",
   "metadata": {},
   "source": [
    "### Min-max or Feature scaling\n",
    "- offset is min of x\n",
    "- spread is the range of x or the max of x minus the min of x\n",
    "- The min of a min-max-normalized variable is zero\n",
    "- The max of a min-max-normalized variable is one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b3909b",
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = min(x)\n",
    "spread = max(x) - min(x)\n",
    "X['xNormMinMax'] = (x - offset)/spread\n",
    "print(\" The min-max-normalized variable has values from 0 to 1\")\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76f2ed8",
   "metadata": {},
   "source": [
    "### Z-Normalization or Standard Normalization or Standard Scoring\n",
    "- offset is mean of x (The mean of a z-normalized variable is zero)\n",
    "- spread is standard deviation of x (The standard deviation of a z-normalized variable is one)\n",
    "- Most of the values are between -2 and +2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3a9e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = np.mean(x)\n",
    "spread = np.std(x)\n",
    "X['xNormZ'] = (x - offset)/spread\n",
    "print(\" The Z-normalized variable has most values within -2 and + 2\")\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26db1d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = np.median(x)\n",
    "spread = np.median(np.absolute(x - np.median(x)))\n",
    "X['xNormMad'] = (x - offset)/spread\n",
    "print(\" The MMAD-normalized variable is zeroed around the median\")\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d23f40",
   "metadata": {},
   "source": [
    "### Comparisons of linear Normalizations\n",
    "The above normalizations all have different numbers\n",
    "How do their histograms compare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c54bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize = (14,7))\n",
    "axes[0, 0].hist(x = X.xNormTrivial, bins=8)\n",
    "axes[0, 0].set_title('Trivial Normalization', y=1.0, pad=-14)\n",
    "axes[0, 1].hist(x = X.xNormMinMax,  bins=8)\n",
    "axes[0, 1].set_title('MinMax Normalization', y=1.0, pad=-14)\n",
    "axes[1, 0].hist(x = X.xNormZ,       bins=8)\n",
    "axes[1, 0].set_title('Z Normalization', y=1.0, pad=-14)\n",
    "axes[1, 1].hist(x = X.xNormMad,     bins=8)\n",
    "axes[1, 1].set_title('MMAD Normalization', y=1.0, pad=-14);\n",
    "fig.suptitle('Compare linear normalization methods');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcdad03",
   "metadata": {},
   "source": [
    "### What is the difference between these normalizations?\n",
    "The histograms (distributions) all look alike except for the x-axis values. A linear normalization will not change the shape of the histogram (distribution).  The normalization will only shift and rescale the x-axis of the histogram."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5951ae2",
   "metadata": {},
   "source": [
    "## Min-Max-Normalization versus Z-Normalization\n",
    "The two most common normalizations are min-max and Z-normalization.  One major purpose for normalizing variables, is to put the values of variables on par with each other.  In other words, normalizations should adjust the scale of variables so that the scales are similar.\n",
    "- Create two variables, one with a high outlier, one with a low outlier\n",
    "- Overlay histograms\n",
    "    - Overlay the histograms of the two original variables\n",
    "    - Overlay the histograms of the two Min-Max Normalized variables\n",
    "    - Overlay the histograms of the two Z-normalized variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c02079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable 1\n",
    "sigma1 = 1\n",
    "mu1a = 3\n",
    "mu1b = 7\n",
    "x1 = np.array(15)\n",
    "x1 = np.append(x1, mu1a + sigma1*np.random.randn(100))\n",
    "x1 = np.append(x1, mu1b + sigma1*np.random.randn(50))\n",
    "x1 = x1.reshape(-1,1)\n",
    "\n",
    "# Variable 2\n",
    "sigma2 = 0.5\n",
    "mu2a = 8.9\n",
    "mu2b = 10.1\n",
    "x2 = np.array(2.5)\n",
    "x2 = np.append(x2, mu2b + sigma2*np.random.randn(150))\n",
    "x12 = x2.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af7ff20",
   "metadata": {},
   "source": [
    "### Overlay Histograms of Original Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a162a444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the original variables by overlaying histograms\n",
    "plt.hist(x1, bins = 20, color=[0, 0, 1, 0.5])\n",
    "plt.hist(x2, bins = 20, color=[1, 0.7, 0, 0.5])\n",
    "plt.title(\"Compare variables \\n without normalization\", y=1.0, pad=-28, loc='left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e31800e",
   "metadata": {},
   "source": [
    "#### Compare Distributions\n",
    "- Are the scales of the two variables significantly different?  \n",
    "- If so, how are they different?\n",
    "- Compare the values of each histogram's x-coordinate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef9c855",
   "metadata": {},
   "source": [
    "### Overlay Histograms of Min-Max Normalized Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf7658d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change both variables by Min-Max Normalization\n",
    "x1NormMinMax = (x1 - np.min(x1))/(np.max(x1) - np.min(x1))\n",
    "x2NormMinMax = (x2 - np.min(x2))/(np.max(x2) - np.min(x2))\n",
    "# Compare the Min-Max-normalized variables by overlaying histograms\n",
    "plt.hist(x1NormMinMax, bins = 20, color=[0, 0, 1, 0.5])\n",
    "plt.hist(x2NormMinMax, bins = 20, color=[1, 0.7, 0, 0.5])\n",
    "plt.title(\"Compare variables after \\n Min-Max Normalization\", y=1.0, pad=-28, loc='left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5cf45e",
   "metadata": {},
   "source": [
    "#### Compare Min-Max-Normalized Distributions\n",
    "- Are the Min-Max normalized scales of the variables significantly different?  \n",
    "- If so, how are they different?\n",
    "- Compare the values of each histogram's x-coordinate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c2ce39",
   "metadata": {},
   "source": [
    "### Overlay Histograms of Z-Normalized Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2708a882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change both variables by Z-Normalization\n",
    "x1NormZ = (x1 - np.mean(x1))/np.std(x1)\n",
    "x2NormZ = (x2 - np.mean(x2))/np.std(x2)\n",
    "# Compare the Z-normalized variables by overlaying histograms\n",
    "plt.hist(x1NormZ, bins = 20, color=[0, 0, 1, 0.5])\n",
    "plt.hist(x2NormZ, bins = 20, color=[1, 0.7, 0, 0.5])\n",
    "plt.title(\"Compare variables \\n after Z-normalization\", y=1.0, pad=-28, loc='left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaad22e",
   "metadata": {},
   "source": [
    "#### Compare Z-Normalized Distributions\n",
    "- Are the scales of the variables significantly different?  \n",
    "- If so, how are they different?\n",
    "- Compare the values of each histogram's x-coordinate\n",
    "  \n",
    "By-the-way **Median-Medain Absolute Deviation (MMAD)** works just as well or even better than Z-normalization for these cases where outliers dominate the scale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef4ee6e",
   "metadata": {},
   "source": [
    "## Use scikit-learn (sklearn) for Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc555df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Z-Normalize with scikit-learn\n",
    "Scaler = StandardScaler()\n",
    "Scaler.fit(x1)\n",
    "Z_sklearn = Scaler.transform(x1)\n",
    "print('scikit-learn std is:', Scaler.scale_[0], '; scikit-learn mean is: ', Scaler.mean_[0])\n",
    "\n",
    "# Z-Normalize with numpy\n",
    "Z_numpy = (x1 - np.mean(x1))/np.std(x1) # np.std(x1) is spread;  np.mean(x1) is offset\n",
    "print('       numpy std is:', np.std(x1),';        numpy mean is: ', np.mean(x1))\n",
    "\n",
    "# Compare the scikit-learn normalization with the numpy normalization\n",
    "fig, axes = plt.subplots(1, 2, figsize = (14,3))\n",
    "axes[0].hist(Z_sklearn, bins = 20)\n",
    "axes[1].hist(Z_numpy,   bins = 20)\n",
    "axes[0].set_title('sklearn StandardScaler', y=1.0, pad=-14)\n",
    "axes[1].set_title('(x1 - np.mean(x1))/np.std(x1)', y=1.0, pad=-14);\n",
    "fig.suptitle(' Compare normalization using numpy vs sklearn ');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb04270",
   "metadata": {},
   "source": [
    "#### Conclusion: scikit-learn and numpy normalizations are equivalent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f9d750",
   "metadata": {},
   "source": [
    "## Compounding Linear Normalizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1700922e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z-Normalize the variable\n",
    "Z = StandardScaler().fit_transform(x1)\n",
    "\n",
    "# Min-Max-Normalize the variable\n",
    "MinMax = MinMaxScaler().fit_transform(x1)\n",
    "\n",
    "# Double Normalized:  Z-Normalize the Min-Max-Normalized variable\n",
    "MinMax_Z = StandardScaler().fit_transform(MinMax)\n",
    "\n",
    "# Double Normalized:  Z-Normalize the Z-Normalized variable\n",
    "Z_Z = StandardScaler().fit_transform(Z)\n",
    "\n",
    "# Double Normalized:  Min-Max-Normalize the Min-Max-normalized variable\n",
    "MinMax_MinMax = MinMaxScaler().fit_transform(MinMax)\n",
    "\n",
    "# Double Normalized:  Min-Max-Normalize the Z-normalized variable\n",
    "Z_MinMax = MinMaxScaler().fit_transform(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15538bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 2, figsize = (14,9))\n",
    "axes[0, 0].hist(Z, bins = 20)\n",
    "axes[0, 0].set_title('only Z', y=1.0, pad=-28)\n",
    "axes[0, 1].hist(MinMax, bins = 20)\n",
    "axes[0, 1].set_title('only MinMax', y=1.0, pad=-28)\n",
    "axes[1, 0].hist(MinMax_Z, bins = 20)\n",
    "axes[1, 0].set_title('1st MinMax\\n2nd Z', y=1.0, pad=-28)\n",
    "axes[1, 1].hist(Z_MinMax, bins = 20)\n",
    "axes[1, 1].set_title('1st Z\\n2nd MinMax', y=1.0, pad=-28)\n",
    "axes[2, 1].hist(MinMax_MinMax, bins = 20)\n",
    "axes[2, 1].set_title('1st MinMax\\n2nd MinMax', y=1.0, pad=-28)\n",
    "axes[2, 0].hist(Z_Z, bins = 20)\n",
    "axes[2, 0].set_title('1st Z\\n2nd Z', y=1.0, pad=-28);\n",
    "fig.suptitle('Compare the x-axis values!');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e95cac2",
   "metadata": {},
   "source": [
    "#### Conclusion: Last Normalization Method is the only normalization that counts!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372d6331",
   "metadata": {},
   "source": [
    "## De-normalize\n",
    "\n",
    "Reverse a normalization for whenever you want to know the value in its original context.  For instance if we want to know the original value of something in normalized space.  Or, you want to know the original value at the 75th percentile.\n",
    " \n",
    "Remember that linear normalization applies this pattern: \n",
    "\n",
    "`xNorm = (x - offset)/spread` \n",
    "\n",
    "Where: \n",
    "- x is a numeric variable\n",
    "- offset is a scalar that shifts variable x lower or higher\n",
    "- spread is a scalar that re-scales variable x to a smaller or larger spread\n",
    "- xNorm is the normalized variable\n",
    "\n",
    "Reverse normalization is:\n",
    "`x = xNorm*spread + offset` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece5070c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Original    ', 'min:{:0.2f}; mean:{:0.2f}; max:{:0.2f}; std:{:0.2f}'.\n",
    "      format(np.min(x1), np.mean(x1), np.max(x1), np.std(x1)))\n",
    "\n",
    "# Z-Normalize the variable\n",
    "offset = np.mean(x1)\n",
    "spread = np.std(x1)\n",
    "xNorm = (x1 - offset)/spread\n",
    "\n",
    "print('Z-Normalized', 'min:{:0.2f}; mean:{:0.2f}; max:{:0.2f}; std:{:0.2f}'.\n",
    "      format(np.min(xNorm), np.mean(xNorm), np.max(xNorm), np.std(xNorm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a871ba",
   "metadata": {},
   "source": [
    "### The wrong way to denormalize\n",
    "Get the offset and spread from the normalized variable and apply them to the de-normalization formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5721a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incorrect Denormilaztion\n",
    "offset = np.mean(xNorm)\n",
    "spread = np.std(xNorm)\n",
    "x1_wrong = xNorm*np.std(xNorm) + np.mean(xNorm)\n",
    "\n",
    "print('Wrong way De-normalized', 'min:{:0.2f}; mean:{:0.2f}; max:{:0.2f}; std:{:0.2f}'.\n",
    "      format(np.min(x1_wrong), np.mean(x1_wrong), np.max(x1_wrong), np.std(x1_wrong)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce845a9",
   "metadata": {},
   "source": [
    "#### Why is above denormalization attempt incorrect?\n",
    "We want the denormalized variable to be the same as the original variable.\n",
    "Compare the values of the x-coordinates (min, mean, max, std) of this denormalization attempt with the x-coordinates of the original and the normalized variables.\n",
    "What are the values of the spread and offset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3002e499",
   "metadata": {},
   "source": [
    "### Correct Denormalization\n",
    "Get the offset and spread from the original variable and apply them to the de-normalization formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a95381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct Denormilaztion\n",
    "offset = np.mean(x1)\n",
    "spread = np.std(x1)\n",
    "x1_correct = xNorm*spread + offset\n",
    "\n",
    "print('Correctly De-normalized', 'min:{:0.2f}; mean:{:0.2f}; max:{:0.2f}; std:{:0.2f}'.\n",
    "      format(np.min(x1_correct), np.mean(x1_correct), np.max(x1_correct), np.std(x1_correct)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218834f5",
   "metadata": {},
   "source": [
    "#### Why is above denormalization attempt correct?\n",
    "We want the denormalized variable to be the same as the original variable.  Therefore, we need to use the same parameters in the de-normalization formula that we used in the normalization formula.\n",
    "\n",
    "Compare the values of the x-coordinates (min, mean, max, std) of this denormalization attempt with the x-coordinates of the original and the normalized variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb7c797",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
