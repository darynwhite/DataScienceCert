{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "\n",
    "We saw a few examples of machine learning algorithms, so at this point it seems like once you get the data ready, machine learning is just \"plug and play\", but not so fast! \n",
    "\n",
    "In this assignment, we learn about **regularization**! Regularization is a means by which we can control how much a machine learning algorithm learns. The controlling is done using a parameter that the algorithm, called the **shrinkage parameter**, which is just an argument of the algorithm. The shrinkage parameter is an example of a **hyper-parameter**. A hyper-parameter is like a knob: by specifying a different value for the hyper-parameter, we control how the training happens, a process called **hyper-parameter tuning**. We talk about this is more detail in the next lesson.\n",
    "\n",
    "We will look at two examples of regularizaiton: LASSO and Ridge regression. Both LASSO and Ridge regression are implementations of linear regression where we try to minimize prediction error plus some penalty that depends on the model's parameters (or coefficients) and the shrinkage constant (`alpha` in the code below). LASSO penalizes the model's parameters using the sum of the **absolute values** of the parameters (this is also called **L1-regularization**), while Ridge does so based on the sum of the **squared values** of the parameters (this is also called **L2-regularization**). For reasons we cannot elaborate on here, **LASSO has the by-product that it also does feature selection**, whereas Ridge doesn't. So not all regularization results in feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from plotly import express as px\n",
    "import sklearn, sklearn.metrics, sklearn.model_selection, sklearn.preprocessing, sklearn.linear_model\n",
    "pd.options.plotting.backend = 'plotly'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Root Mean Squared Error (RMSE)\n",
    "Before we dive into regularization we need to have a metric that tells us if our regression is good or bad.  For regressions we measure success differently than with classifications.  Instead of accuracy, the primary measure is **Root Mean Squared Error** (**RMSE**).  A **RMSE** of zero occurs when the predictions are perfect. **RMSE** increases as the predictions get worse. Let's disect the term **Root Mean Squared Error** by understanding each word from right to left.\n",
    "\n",
    "### Error\n",
    "The **E** in **RMSE** stands for **E**rror ($e_i$).  The error ($e_i$) is the difference between the known test target value ($y_i$) of sample $i$ and the predicted target value ($\\hat{y}_i$) based on the test inputs of sample $i$.\n",
    "$$e_i = y_i - \\hat{y}_i$$\n",
    "where\n",
    "- $e_i$ is the error of the $i$th sample\n",
    "- $y_i$ is the test target value of the $i$th sample\n",
    "- $\\hat{y}_i$ is the predicted target value from the inputs of the $i$th sample\n",
    "\n",
    "### Squared\n",
    "The **S** in **RMSE** stands for squared.  The errors ($e_i$) are squared: $(e_i)^2$.  \n",
    "\n",
    "### Mean\n",
    "The **M** in **RMSE** stands for mean.  We get the mean squared error (**MSE**) by taking the mean of all the squared errors in the sample:\n",
    "$$\\text{MSE} = \\frac{1}{n}\\sum_{i}(e_i)^2$$\n",
    "where\n",
    "- $\\text{MSE}$ is the mean squared error\n",
    "- $n$ is the number of samples\n",
    "\n",
    "### Root\n",
    "The **R** in **RMSE** stands for root.  We get the root mean squared error (**RMSE**) by taking the square root mean of **MSE**\n",
    "$$\\text{RMSE} = \\sqrt{\\text{MSE}}$$\n",
    "\n",
    "Both **MSE** and **RMSE** are used to measure the prediction error.  **RMSE** is often preferred because it is in the units of the target variable ($y$), whereas **MSE** is in units of the target variable squared ($y^2$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Coding starts here\n",
    "0. Compute error metrics.  \n",
    "<br/>\n",
    "To make sure we understand RMSE, lets do one small exercise.\n",
    "\n",
    "We have the following data:\n",
    "- The actual test target values are: `20, 15, 12, 17, 15, 14, 19, 17`\n",
    "- The predicted target values predicted from test inputs are: `19, 12, 12, 19, 17, 17, 17, 18`\n",
    "\n",
    "Determine and show\n",
    "1. the 8 errors\n",
    "2. the 8 squared errors derived from the errors\n",
    "3. the MSE derived from the 8 squared errors\n",
    "4. the RMSE derived from the MSE\n",
    "5. the RMSE derived from the actual test target values and the predicted target values using sklearn.metrics.mean_squared_error with squared=False\n",
    "<br/><span style=\"color:red\" float:right>[1 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Code here\n",
    "err_dat = pd.DataFrame([20, 15, 12, 17, 15, 14, 19, 17], columns=['values'])\n",
    "err_dat['predicted'] = [19, 12, 12, 19, 17, 17, 17, 18]\n",
    "err_dat['error'] = err_dat['values'] - err_dat['predicted']\n",
    "err_dat['squares'] = err_dat['error'] ** 2\n",
    "\n",
    "err_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = err_dat['squares'].mean()\n",
    "rmse = np.sqrt(mse)\n",
    "sk_rmse = sklearn.metrics.mean_squared_error(err_dat['values'],err_dat['predicted'], squared=False)\n",
    "\n",
    "print(f\"The MSE is {mse}\\nThe RMSE is {rmse}\\nAnd SciKit RMSE {sk_rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization\n",
    "Let's get back to the main portion of this assignment.  As always we will need data before we can do our work.  Here we will use the California Housing Data from the 1990 census.  We will create regressions that predict the median house value in Californian communities.  You can find a description here:  https://www.kaggle.com/datasets/camnugent/california-housing-prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get California Housing Data\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "HousingCal = fetch_california_housing()\n",
    "# 20640 rows Ã— 9 columns\n",
    "# MedInc, HouseAge, AveRooms, AveBedrms, Population, AveOccup, Latitude, Longitude, MedHouseVal\n",
    "df_housing = pd.DataFrame(data=HousingCal['data'], columns=HousingCal['feature_names'])\n",
    "df_housing[HousingCal['target_names'][0]] = HousingCal['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Present the size of the data frame and the first few rows and a histogram for `MedHouseVal`. \n",
    "\n",
    "<span style=\"color:red\" float:right>[0 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add code here\n",
    "display(df_housing.shape,df_housing['MedHouseVal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(df_housing['MedHouseVal'],template='seaborn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is better to create a model that is limited in its scope, than to include data that are difficult to interpret.  In this case, we opt for a model that will only determine median house values up to 5 ($500,000).  The median house values for communities greater or equal to 5, are mostly incorrect.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Prepare the data by doing the following:\n",
    "\n",
    "    1. remove the communities (rows) where `MedHouseVal` is greater or equal to 5 and present another histogram of `MedHouseVal`\n",
    "    2. remove `Latitude` and `Longitude` because we haven't learned yet how to make these useful\n",
    "    3. split the data into features and target\n",
    "    4. split the features and target into training and test sets\n",
    "    5. normalize the training and test features based on the training data\n",
    "\n",
    "    <span style=\"color:red\" float:right>[1 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add code here\n",
    "# remove the houses where `MedHouseVal` is greater or equal to 5\n",
    "df_housing.drop(df_housing[df_housing['MedHouseVal'] >= 5].index,inplace=True)\n",
    "# Present histogram of MedHouseVal\n",
    "px.histogram(df_housing['MedHouseVal'],template='seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add code here\n",
    "# remove `Latitude` and `Longitude`\n",
    "df_housing.drop(labels=['Latitude','Longitude'], axis=1, inplace=True)\n",
    "df_housing.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add code here\n",
    "# split the data into features and target\n",
    "features = df_housing.drop('MedHouseVal',axis=1)\n",
    "target = df_housing['MedHouseVal']\n",
    "# split the features and target into training and test sets\n",
    "feat_train, feat_test, targ_train, targ_test = sklearn.model_selection.train_test_split(features,target,test_size=0.15,random_state=41)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_test.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the training and test features based on the training data\n",
    "normie = sklearn.preprocessing.StandardScaler()\n",
    "normie.fit(feat_train)\n",
    "X_train = pd.DataFrame(normie.transform(feat_train),columns=feat_train.columns)\n",
    "X_test = pd.DataFrame(normie.transform(feat_test),columns=feat_test.columns)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Train and Predict\n",
    "    - Train a linear regression algorithm, using `LinearRegression` from `sklearn.linear_model`, to predict `MedHouseVal` on the prepared data.\n",
    "    - predict the median house prices for both training and test data sets.  These predictions will serve as benchmarks.\n",
    "    \n",
    "    <span style=\"color:red\" float:right>[1 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add code here\n",
    "y_train = targ_train\n",
    "linreg = sklearn.linear_model.LinearRegression()\n",
    "linreg.fit(X_train, y_train)\n",
    "\n",
    "y_hat_train_benchmark = linreg.predict(X_train)\n",
    "y_hat_test_benchmark = linreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Evaluate the model\n",
    "\n",
    "    Calculate and report the performance (RMSE) on both training and test data. These numbers will serve as our benchmark performance. As a sanity check, create a scatter plot of the bench mark predictions against the actual values. Create this plot for both the training and test data sets.\n",
    "\n",
    "    <span style=\"color:red\" float:right>[2 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add code here\n",
    "# Calculate and report RMSE\n",
    "print(f\"\"\"The training benchmark is: {sklearn.metrics.mean_squared_error(targ_train.values,y_hat_train_benchmark, squared=False):0.5f}\n",
    "The testing benchmark is: {sklearn.metrics.mean_squared_error(targ_test.values,y_hat_test_benchmark, squared=False):0.5f}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add code here\n",
    "evaluation = pd.DataFrame(targ_test.values,columns=['target_values'])\n",
    "evaluation['linear_predicted_values'] = y_hat_test_benchmark\n",
    "# scatter plot of the bench mark predictions against the actual values\n",
    "px.scatter(evaluation,x='target_values',y='linear_predicted_values',template='seaborn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now train a regularized version of `LinearRegression` called `Lasso` (you can load it from the sklearn.linear_model.Lasso). `Lasso` has an argument called `alpha`, which is the **shrinkage parameter** we referred to earlier.\n",
    "\n",
    "4. Let `alpha = 0.000001` and train a `Lasso` model. Show that the resulting model is practically identical to the one we trained with `LinearRegression`. There are different ways to show this, so you will need to think of a way. \n",
    "\n",
    "    <span style=\"color:red\" float:right>[2 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = sklearn.linear_model.Lasso(alpha=0.000001)\n",
    "lasso.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluation['lasso_predicted_values'] = lasso.predict(X_test)\n",
    "px.histogram(\n",
    "    evaluation.diff(axis=1)['lasso_predicted_values'],\n",
    "    x='lasso_predicted_values',\n",
    "    template='seaborn',\n",
    "    title='Difference between Linear and Lasso (alpha=0.000001)',\n",
    "    labels={'lasso_predicted_values':'difference'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(evaluation,x='linear_predicted_values',y='lasso_predicted_values')\n",
    "fig.add_shape(type='line',x0=-3,y0=-3,x1=9,y1=9, line=dict(color=\"LightSeaGreen\",width=1,dash=\"dot\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comment on the comparison\n",
    "\n",
    "> The difference between the Linear regression and the Lasso regression with alpha at 0.000001 is so small it is insignificant. Most values are with 0.000004"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Get regression coefficients and performance metrics for varying alpha.  The performance metrics are  RMSE for training and test data.  \n",
    "\n",
    "    <span style=\"color:red\" float:right>[5 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The alpha column contains the values we want to iterate over\n",
    "# The other columns are for storing the coefficients of the lasso regressions\n",
    "X = feat_train\n",
    "Coefficients = pd.DataFrame(data=np.arange(0.01, 1, .01), columns=['alpha'])\n",
    "Coefficients[list(X.columns) + ['RMSE_train', 'RMSE_test']] = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make it easier, we have laid out a suggestion for the code. You can use our layout or you can design your own code.\n",
    "For each iteration in the suggested design:    \n",
    "- Train a new `Lasso` model, letting `alpha` change each time to one of the values given by `alpha_vals` below.  \n",
    "- For each value of `alpha` in `Coefficients`, retrieve the coefficients from the `coef_` attribute of the trained model. \n",
    "- Store the coefficients in `Coefficients`\n",
    "- Predict the training labels, e.g. `y_hat_train`\n",
    "- Determine the rmse of the training data, e.g. `rmse_train`\n",
    "- Store the rmse of the training data in `Coefficients`\n",
    "- Predict the test labels, e.g. `y_hat_test`\n",
    "- Determine the rmse of the test data, e.g. `rmse_test`\n",
    "- Store the rmse of the test data in `Coefficients`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add code here\n",
    "# loop over the alpha values and do this:\n",
    "for n,alpha in enumerate(Coefficients.alpha):\n",
    "    # instantiate a Lasso regression with alpha\n",
    "    lasso_run = sklearn.linear_model.Lasso(alpha=alpha)\n",
    "    # fit the lasso regression\n",
    "    lasso_run.fit(X_train,y_train)\n",
    "    # add the coefficients to the DataFrame row\n",
    "    Coefficients.loc[n,X.columns] = lasso_run.coef_\n",
    "    # predict training labels (y_hat for training)\n",
    "    # determine training error metric (RMSE)\n",
    "    # add the training error metric (RMSE) to the DataFrame row\n",
    "    Coefficients.loc[n,'RMSE_train'] = sklearn.metrics.mean_squared_error(targ_train.values,lasso_run.predict(X_train), squared=False)\n",
    "    # predict test labels (y_hat for test)\n",
    "    # determine test error metric (RMSE)\n",
    "    # add the test error metric (RMSE) to the DataFrame row\n",
    "    Coefficients.loc[n,'RMSE_test'] = sklearn.metrics.mean_squared_error(targ_test.values,lasso_run.predict(X_test), squared=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Coefficients.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Lasso changes with alpha\n",
    "\n",
    "    (a) Using a visual, show how the performance on the training and test data changed as we gradually increased the shrinkage parameter `alpha`. At which point is there a substantial decrease in performance (increase in RMSE) on the test data?  You might want to use a log scale (`plt.xscale('log')`) for `alpha`.\n",
    "\n",
    "    (b) Using a visual, show how the model's coefficients changed as we gradually increased the shrinkage parameter `alpha`. HINT: They should appear to be shrinking toward zero as you increase `alpha`. \n",
    "\n",
    "    <span style=\"color:red\" float:right>[4 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add code here\n",
    "# RMSE vs. alpha\n",
    "px.bar(Coefficients[:70],x='alpha',y=['RMSE_train','RMSE_test'],template='seaborn',barmode='group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add code here\n",
    "# Coefficient vs. alpha\n",
    "px.bar(Coefficients[:70],x='alpha',y=list(X.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Compare `Ridge` and `Lasso` baseline models.  Show that `Ridge` and `Lasso` return the same trained model when `alpha = 0.00001` (i.e. close to zero). <br/><span style=\"color:red\" float:right>[1 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add code here\n",
    "ridge = sklearn.linear_model.Ridge(alpha=0.000001)\n",
    "# fit the ridge regression\n",
    "ridge.fit(X_train,y_train)\n",
    "# compare the coefficients\n",
    "print(f\"\"\"Ridge coefficients: {ridge.coef_}\n",
    "Lasso coefficients: {lasso.coef_}\\n\"\"\")\n",
    "# compare predicted test labels (y_hat for test)\n",
    "print(f\"\"\"Ridge predictions: {ridge.predict(X_test)[:6]}\n",
    "Lasso predictions: {lasso.predict(X_test)[:6]}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Get regression coefficients and performance metrics for varying `alpha` on a ridge regression.  The performance metrics are  RMSE for training and test data.  In other words, repeat the above using `Ridge` instead of `Lasso`.   For `ridge`, we will use the following range for `alpha`: `np.power(2., np.arange(1., 25., 1.))`\n",
    "\n",
    "    > Note: Ridge has a  different behaviour than Lasso. Coefficients will very gradually approach zero and not have a steep drop off. You probably will not notice any zero coefficients.\n",
    "\n",
    "    <span style=\"color:red\" float:right>[1 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add code here\n",
    "# Determine alpha_values\n",
    "# The alpha column contains the values we want to iterate over\n",
    "# The other columns are for storing the coefficients of the ridge regressions\n",
    "Coefficients_R = pd.DataFrame(data=np.power(2., np.arange(1., 25., 1.)), columns=['alpha'])\n",
    "Coefficients_R[list(X.columns) + ['RMSE_train', 'RMSE_test']] = np.nan\n",
    "\n",
    "for n,alpha in enumerate(Coefficients_R.alpha):\n",
    "    lasso_run = sklearn.linear_model.Ridge(alpha=alpha)\n",
    "    lasso_run.fit(X_train,y_train)\n",
    "    Coefficients_R.loc[n,X.columns] = lasso_run.coef_\n",
    "    Coefficients_R.loc[n,'RMSE_train'] = sklearn.metrics.mean_squared_error(targ_train.values,lasso_run.predict(X_train), squared=False)\n",
    "    Coefficients_R.loc[n,'RMSE_test'] = sklearn.metrics.mean_squared_error(targ_test.values,lasso_run.predict(X_test), squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Coefficients_R.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Ridge changes with alpha\n",
    "<br/>\n",
    "(a) Using a visual, show how the performance on the training and test data changed as we gradually increased `alpha` for `Ridge`. In other words, repeat the above using `Ridge` instead of `Lasso`.  \n",
    "<br/>\n",
    "(b) Using a visual, show how the model's coefficients for ridge changed as we gradually increased the shrinkage parameter `alpha`.  \n",
    "<br/><span style=\"color:red\" float:right>[2 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add code here\n",
    "# RMSE vs. alpha\n",
    "px.scatter(Coefficients_R,x='alpha',y=['RMSE_train','RMSE_test'],template='seaborn',log_x=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add code here\n",
    "# Coefficient vs. alpha\n",
    "px.scatter(Coefficients_R[:25],x='alpha',y=list(X.columns),log_x=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Based on the results, briefly describe the effect of changing `alpha` on the coefficients of both `Ridge` and `Lasso`. What value of `alpha` would you choose for each case? You do not need to give a precise answer, but choose a number. <br/><span style=\"color:red\" float:right>[2 point]</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comments on regularization using ridge and lasso\n",
    "\n",
    "> Changing the `alpha` of either `Ridge` or `Lasso` seems to decrease the effect of all coefficients. In both it seems to leave an isolated single variable as the predictor, at least for this dataset. \n",
    "\n",
    "> For the `Lasso` regression I would choose a number around `0.005 to 0.01` and for the `Ridge` regression I would choose something between `1 to 5`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# End of assignment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
